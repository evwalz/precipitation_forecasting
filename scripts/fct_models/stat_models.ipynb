{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925d9173-9f1c-493e-82d8-9a5fb56a1b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data download and processing is described in paper and in repository EPC\n",
    "# Provide data and code to reproduce figure 7 (then people should easily be able to reproduce all other figures as well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e5fbba0-913d-41b8-8592-ecece34946d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db2b2841-5d16-42f1-868a-3eb2581ca660",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../precip_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6dcb09e4-aaf1-45d6-84ee-3107f2a4d7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_save = data_dir + '/results/'\n",
    "data_save2 = data_dir + '/results/full_models/'\n",
    "lsm = np.loadtxt(data_dir  + \"/lsm.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10e82397-ae05-4c03-90e3-67df14fe6fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_full = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2536fd63-e7f9-4c1e-b93a-440dd6f8fbec",
   "metadata": {},
   "source": [
    "# DIM and Logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98223c37-c619-4466-a52e-c0d100207f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from isodisreg import idr\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression \n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5d82fbc-2455-4543-857b-dfb8b0d8ad69",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = 'min_max'\n",
    "feature_set = 'v2+time' # for baseline model use 'v1+time'\n",
    "add_time = True\n",
    "season = 'JAS'\n",
    "model_type = 'logit' # 'dim' or 'logit'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6abeaf35-ff56-43da-841d-8555e6b1ef9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set_name = feature_set[0:2]\n",
    "baseline = False\n",
    "if feature_set_name == 'v1':\n",
    "    baseline = True\n",
    "\n",
    "if model_type == 'logit':\n",
    "    model = LogisticRegression(max_iter = 500)\n",
    "else:\n",
    "    model = LinearRegression()  \n",
    "\n",
    "if baseline:\n",
    "    model_name = model_type + '_base'\n",
    "else:\n",
    "    model_name = model_type\n",
    "    \n",
    "folds = np.arange(9)\n",
    "\n",
    "crps_fold = np.zeros(len(folds))\n",
    "bs_fold = np.zeros(len(folds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9d5e7af-ea3b-40fb-9c9a-dfe3e3e32dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "if model_type == 'logit':\n",
    "\n",
    "    for fold in folds:\n",
    "        print(fold)\n",
    "\n",
    "        \n",
    "        bs_cv = np.zeros((19, 61))\n",
    "\n",
    "        paths = PrecipitationDataPaths()\n",
    "        feature_set_train, feature_set_test = select_data_subset(paths=paths, version=feature_set, fold=fold)\n",
    "        Xtrain_prev, ytrain = load_and_concat(data_dir, fold, feature_set_train, add_time = add_time, mode = \"train\")\n",
    "        if fold == 8:\n",
    "            Xval_prev, yval = load_and_concat(data_dir, fold, feature_set_test, add_time = add_time, mode = \"test\")\n",
    "        else:\n",
    "            Xval_prev, yval = load_and_concat(data_dir, fold, feature_set_train, add_time = add_time, mode = \"val\")\n",
    "    \n",
    "        scaler_inputs = PerFeatureMeanStdScaler()\n",
    "\n",
    "        Xtrain = scaler_inputs.fit_transform(Xtrain_prev)\n",
    "        Xval = scaler_inputs.transform(Xval_prev)\n",
    "\n",
    "        year_dim = yval.shape[0]\n",
    "        ix0, ix1 = sel_season_indx(season, year_dim)\n",
    "\n",
    "        if save_full:\n",
    "            model_bs = xr.DataArray(\n",
    "               np.random.rand(19, 61),\n",
    "               coords=[np.arange(19) ,np.arange(-25, 35.5) ],\n",
    "               dims=[\"lat\", \"lon\"],\n",
    "               name='var'\n",
    "            )\n",
    "\n",
    "        for i in range(19):\n",
    "            for j in range(61):\n",
    "                if lsm[i, j] != 0:\n",
    "                    obs_train_bin = ytrain[:, i, j] > 0.2\n",
    "                    obs_test_bin = yval[ix0:ix1, i, j] > 0.2\n",
    "                    if np.sum(obs_train_bin) == 0:\n",
    "                        probs_rain = np.zeros(len(obs_test_bin))\n",
    "                        bs_cv[i, j] = np.mean((probs_rain - obs_test_bin) ** 2)\n",
    "                    else:\n",
    "                        clf = model.fit(Xtrain[:, :, i, j], obs_train_bin)\n",
    "                        probs_rain = clf.predict_proba(Xval[ix0:ix1 , :, i, j])[:, 1]\n",
    "                        bs_cv[i, j] = np.mean((probs_rain - obs_test_bin) ** 2)\n",
    "                else:\n",
    "                    bs_cv[i, j] = np.nan\n",
    "                \n",
    "\n",
    "        bs_fold[fold] = np.nanmean(bs_cv)\n",
    "        \n",
    "        if save_full:\n",
    "            model_bs[:, :] = bs_cv\n",
    "            model_bs.to_netcdf(data_save2 + model_name + '_bs_' + season + '_' + str(fold) +'.nc')\n",
    "\n",
    "    np.savetxt(data_save + model_name + '_bs_'+ str(feature_set)+ '_' + season + '.txt', bs_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c929e4e-ad82-4fe5-b5a4-410f45c4019f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91de37be-93af-4dcd-a3fe-f308529d4028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dim'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c456c96-fcca-4599-8f4a-90284699d493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "if model_type == 'dim':\n",
    "    for fold in folds:\n",
    "        print(fold)\n",
    "        crps_cv = np.zeros((19, 61))\n",
    "        bs_cv = np.zeros((19, 61))\n",
    "        paths = PrecipitationDataPaths()\n",
    "        feature_set_train, feature_set_test = select_data_subset(paths=paths, version=feature_set, fold=fold)\n",
    "        Xtrain_prev, ytrain = load_and_concat(data_dir, fold, feature_set_train, add_time = add_time, mode = \"train\")\n",
    "        if fold == 8:\n",
    "            Xval_prev, yval = load_and_concat(data_dir, fold, feature_set_test, add_time = add_time, mode = \"test\")\n",
    "        else:\n",
    "            Xval_prev, yval = load_and_concat(data_dir, fold, feature_set_train, add_time = add_time, mode = \"val\")\n",
    "    \n",
    "        scaler_inputs = PerFeatureMeanStdScaler()\n",
    "\n",
    "        Xtrain = scaler_inputs.fit_transform(Xtrain_prev)\n",
    "        Xval = scaler_inputs.transform(Xval_prev)\n",
    "\n",
    "        year_dim = yval.shape[0]\n",
    "        ix0, ix1 = sel_season_indx(season, year_dim)\n",
    "        if save_full:\n",
    "            model_bs = xr.DataArray(\n",
    "               np.random.rand(19, 61),\n",
    "               coords=[np.arange(19) ,np.arange(-25, 35.5) ],\n",
    "               dims=[\"lat\", \"lon\"],\n",
    "               name='var'\n",
    "            )\n",
    "            model_crps = xr.DataArray(\n",
    "               np.random.rand(19, 61),\n",
    "               coords=[np.arange(19) ,np.arange(-25, 35.5) ],\n",
    "               dims=[\"lat\", \"lon\"],\n",
    "               name='var'\n",
    "            )\n",
    "            \n",
    "        for i in range(19):\n",
    "            for j in range(61):\n",
    "                if lsm[i, j] != 0:\n",
    "                    ytrain_log = np.log(ytrain[:, i, j] + 0.001)\n",
    "                    reg = model.fit(Xtrain[:, :, i, j], ytrain_log)\n",
    "                    reg_train =  np.exp(reg.predict(Xtrain[:, :, i, j])) - 0.001\n",
    "                    reg_valid = np.exp(reg.predict(Xval[ix0:ix1, :, i, j])) - 0.001\n",
    " \n",
    "                    idr_output = idr(ytrain[:, i, j], pd.DataFrame({'fore': reg_train}, columns = ['fore']))\n",
    "                \n",
    "                    pred_idr = idr_output.predict(pd.DataFrame({'fore': reg_valid}, columns = ['fore']))\n",
    "                    crps_cv[i,j] = np.mean(pred_idr.crps(yval[ix0:ix1, i, j]))\n",
    "                    bs_cv[i, j] = np.mean(pred_idr.bscore(thresholds = 0.2, y = yval[ix0:ix1, i, j]))\n",
    "                else:\n",
    "                    crps_cv[i,j] = np.nan\n",
    "                    bs_cv[i, j] = np.nan\n",
    "            \n",
    "        crps_fold[fold] = np.nanmean(crps_cv)\n",
    "        bs_fold[fold] = np.nanmean(bs_cv)\n",
    "\n",
    "        if save_full:\n",
    "            model_bs[:, :] = bs_cv\n",
    "            model_bs.to_netcdf(data_save2 + model_name + '_bs_'+ season + '_' + str(fold) +'.nc')\n",
    "            model_crps[:, :] = crps_cv\n",
    "            model_crps.to_netcdf(data_save2 + model_name + '_crps_'+  season + '_' + str(fold) +'.nc')\n",
    "\n",
    "    np.savetxt(data_save + model_name + '_crps_'+ str(feature_set)+   '_' + season + '.txt', crps_fold)\n",
    "    np.savetxt(data_save + model_name + '_bs_'+ str(feature_set)+  '_' + season + '.txt', bs_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de66c63c-8c1a-44a4-a061-d513ff2c4613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.16225424, 0.15463518, 0.15574375, 0.15937833, 0.16720263,\n",
       "       0.14780643, 0.15391859, 0.1516543 , 0.1480355 ])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crps_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ca59a7-f5aa-470e-9dab-407d09b94ce2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
